{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nimport numpy as np\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model, save_model\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:41:06.777978Z","iopub.execute_input":"2022-06-29T02:41:06.779123Z","iopub.status.idle":"2022-06-29T02:41:15.296844Z","shell.execute_reply.started":"2022-06-29T02:41:06.778989Z","shell.execute_reply":"2022-06-29T02:41:15.295619Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Load and visualize the data","metadata":{}},{"cell_type":"markdown","source":"from experimentation I found image size of 256 worked best","metadata":{}},{"cell_type":"code","source":"img_height = 256\nimg_width = 256\n\nGCS_PATH = KaggleDatasets().get_gcs_path()\n\ntrain_path = \"../input/chest-xray-pneumonia/chest_xray/train\"\ntest_path = \"../input/chest-xray-pneumonia/chest_xray/test\"\nvalid_path = \"../input/chest-xray-pneumonia/chest_xray/val\"\n\nCATEGORIES = [\"NORMAL\", \"PNEUMONIA\"]\n\nfor category in CATEGORIES:\n\tpath = os.path.join(train_path, category)\n\tfor img in os.listdir(path):\n\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n\t\tnew_array = cv2.resize(img_array, (img_width, img_height))\n\t\tplt.imshow(new_array, cmap='gray')\n\t\tplt.show()\n\t\tbreak\n\tbreak","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:42:48.801970Z","iopub.execute_input":"2022-06-29T02:42:48.802701Z","iopub.status.idle":"2022-06-29T02:42:50.099430Z","shell.execute_reply.started":"2022-06-29T02:42:48.802650Z","shell.execute_reply":"2022-06-29T02:42:50.098118Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Data spliting\n\nIt is important that the data is split properly because there are only 7 images in the validation file\n\nI just dragged and dropped to get an 80:20 split. I couldn't do that here so I'll have a lower validation accuracy and a high validation loss.\n\nData Augmentation\n\nI found the values for data augmentation were the best.","metadata":{}},{"cell_type":"code","source":"shear_range = 0.2\nzoom_range = 0.3\nrotation_range = 0\nhorizontal_flip = False\n\ndef img_augmentation(shear_range, zoom_range, rotation_range, horizontal_flip):\n\tglobal train, test, valid\n\timage_gen = ImageDataGenerator(rescale=1/255,\n\t\t\tshear_range=shear_range,\n\t\t\tzoom_range=zoom_range,\n\t\t\trotation_range=rotation_range,\n\t\t\thorizontal_flip=horizontal_flip)\n\n\ttest_data_gen = ImageDataGenerator(rescale=1/255)\n\n\ttrain = image_gen.flow_from_directory(\n\t\ttrain_path,\n\t\ttarget_size=(img_height, img_width),\n\t\tshuffle=True,\n\t\tcolor_mode='grayscale',\n\t\tbatch_size=batch_size,\n\t\tclass_mode='binary',\n\t\t)\n\n\ttest = test_data_gen.flow_from_directory(\n\t\ttest_path,\n\t\ttarget_size=(img_height, img_width),\n\t\tshuffle=False,\n\t\tcolor_mode='grayscale',\n\t\tclass_mode='binary',\n\t\tbatch_size=64\n\t\t)\n\n\tvalid = image_gen.flow_from_directory(\n\t\tvalid_path,\n\t\ttarget_size=(img_height, img_width),\n\t\tcolor_mode='grayscale',\n\t\tshuffle=False,\n\t\tclass_mode='binary',\n\t\tbatch_size=64\n\t\t)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:43:43.579479Z","iopub.execute_input":"2022-06-29T02:43:43.579882Z","iopub.status.idle":"2022-06-29T02:43:43.590630Z","shell.execute_reply.started":"2022-06-29T02:43:43.579849Z","shell.execute_reply":"2022-06-29T02:43:43.589188Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Model building\n\nI expirmented with many different model structures and came across a model with low validation loss","metadata":{}},{"cell_type":"code","source":"class build_model(object):\n\tdef __init__(self, activation, conv_layer, dense_layer, layer_size):\n\t\tself.activation = activation\n\t\tself.conv_layer = conv_layer\n\t\tself.dense_layer = dense_layer\n\t\tself.layer_size = layer_size\n\n\tdef conv_block(self, filter_size):\n\t\tblock = [Conv2D(filter_size, (3, 3), activation=self.activation, input_shape=(img_width, img_height, 1), padding='same'),\n\t\tMaxPooling2D(pool_size=(2, 2))]\n\n\t\tl = 1\n\t\twhile l < self.conv_layer:\n\t\t\tblock.append(Conv2D(filter_size*(2**l), (3, 3), activation=self.activation, padding='same')),\n\t\t\tblock.append(MaxPooling2D(pool_size=(2, 2)))\n\t\t\tblock.append(Dropout(rate=0.2))\n\n\t\t\tl = l + 1\n\n\t\treturn block\n\n\tdef dense_block(self):\n\t\tblock=[Dense(activation=self.activation, units=self.layer_size)]\n\n\t\tl = 2\n\t\twhile l < self.dense_layer+1:\n\t\t\tblock.append(Dense(activation=self.activation, units=self.layer_size/l))\n\t\t\tl = l + 1\n\n\t\t\treturn block","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:44:13.464141Z","iopub.execute_input":"2022-06-29T02:44:13.464580Z","iopub.status.idle":"2022-06-29T02:44:13.478213Z","shell.execute_reply.started":"2022-06-29T02:44:13.464545Z","shell.execute_reply":"2022-06-29T02:44:13.476698Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"I put the model all together in a sequential function","metadata":{}},{"cell_type":"code","source":"def model_add(filter_size, activation, dropout_rate):\n\tglobal model\n\n\tCONV_LAYER = 3\n\tLAYER_SIZE = 128\n\tDENSE_LAYER = 2\n\n\tNN = build_model(activation, CONV_LAYER, DENSE_LAYER, LAYER_SIZE)\n\n\tmodel = Sequential([\n\t\tNN.conv_block(filter_size)[0],\n\t\tNN.conv_block(filter_size)[1],\n\t\tNN.conv_block(filter_size)[2],\n\t\tNN.conv_block(filter_size)[3],\n\t\tNN.conv_block(filter_size)[4],\n\t\tNN.conv_block(filter_size)[5],\n\t\tNN.conv_block(filter_size)[6],\n\t\tNN.conv_block(filter_size)[7],\n\t\tFlatten(),\n\t\tNN.dense_block()[0],\n\t\tNN.dense_block()[1],\n\t\tDropout(rate=0.2),\n\t\tDense(activation='sigmoid', units=1)])\n\n\treturn model","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:44:33.091195Z","iopub.execute_input":"2022-06-29T02:44:33.091591Z","iopub.status.idle":"2022-06-29T02:44:33.101223Z","shell.execute_reply.started":"2022-06-29T02:44:33.091558Z","shell.execute_reply":"2022-06-29T02:44:33.099689Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"then I make my callbacks list and fit the model to my training data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\nclass model_eval(object):\n\tdef __init__(self, train, test, val, epochs):\n\t\tself.train = train\n\t\tself.test = test\n\t\tself.val = val\n\t\tself.epochs = epochs\n\n\tdef balance_classes(self):\n\t\tweights = compute_class_weight(class_weight='balanced', classes=np.unique(train.classes), y=train.classes)\n\t\tcw = dict(zip(np.unique(train.classes), weights))\n\n\t\treturn cw\n\n\n\tdef callback_list(self):\n\t\tearly = EarlyStopping(monitor='val_accuracy', patience=5)\n\n\t\tlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n\t\t\tpatience=1, verbose=1, factor=0.5, min_lr=0.000001)\n\n\t\tcheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", \n\t\t\tsave_best_only=True)\n\n\t\tcallback_list = [early, learning_rate_reduction]\n\n\t\treturn callback_list\n\n\n\tdef train_test(self, optimizer):\n\t\tglobal history\n\t\tmodel_add(32, 'relu', 0.2)\n\t\tmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\t\tmodel.summary()\n\n\t\tcw = self.balance_classes()\n\t\tcallbacks_list = self.callback_list()\n\n\t\thistory = model.fit(self.train, epochs=self.epochs, validation_data=self.val, class_weight=cw, callbacks=callbacks_list)\n\n\t\ttest_accuracy = model.evaluate(self.test)\n\t\tprint('The testing accuracy is: ', test_accuracy[1]*100, '%')\n\n\t\treturn history","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:45:02.180212Z","iopub.execute_input":"2022-06-29T02:45:02.180700Z","iopub.status.idle":"2022-06-29T02:45:02.197136Z","shell.execute_reply.started":"2022-06-29T02:45:02.180667Z","shell.execute_reply":"2022-06-29T02:45:02.195578Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"Then I graph my validation accuracy and validation loss\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n\timg_augmentation(shear_range, zoom_range, rotation_range, horizontal_flip)\n\tepochs = 50\n\n\teval = model_eval(train, test, valid, epochs)\n\teval.train_test('adam')\n\n\taccuracy = history.history['accuracy']\n\tval_accuracy = history.history['val_accuracy']\n\tplt.plot(range(len(accuracy)), accuracy, color='blue', label='Training accuracy')\n\tplt.plot(range(len(accuracy)), val_accuracy, color='red', label='Validation accuracy')\n\tplt.xlabel('Epoch No.')\n\tplt.ylabel('Accuracy')\n\tplt.legend()\n\tplt.show()\n\n\tloss = history.history['loss']\n\tval_loss = history.history['val_loss']\n\tplt.plot(range(len(accuracy)), loss, color='blue', label='Training loss')\n\tplt.plot(range(len(accuracy)), val_loss, color='red', label='Validation loss')\n\tplt.xlabel('Epoch No.')\n\tplt.ylabel('loss')\n\tplt.legend()\n\tplt.show()\n\n\ttrue = test.classes\n\tpreds = model.predict(test, verbose=1)\n\tpredictions = preds.copy()\n\tpredictions[predictions <= 0.5] = 0\n\tpredictions[predictions > 0.5] = 1\n\n\tcm = confusion_matrix(true, np.round(predictions))\n\tfig, ax = plt.subplots()\n\tfig.set_size_inches(12, 8)\n\tsns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, cbar=False)\n\tax.tick_params(axis='x', labelsize=16)\n\tax.tick_params(axis='y', labelsize=16)\n\tax.set_ylabel(\"True\", color=\"royalblue\", fontsize=35, fontweight=700)\n\tax.set_xlabel(\"Prediction\", color=\"royalblue\", fontsize=35, fontweight=700)\n\tplt.yticks(rotation=0)\n\tplt.show()\n\n\tprint(classification_report(y_true=test.classes, y_pred=predictions, target_names=['NORMAL', 'PNEUMONIA']))\n\nif __name__ == '__main__':\n\tmain()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T02:51:30.898590Z","iopub.execute_input":"2022-06-29T02:51:30.899181Z","iopub.status.idle":"2022-06-29T03:09:15.231663Z","shell.execute_reply.started":"2022-06-29T02:51:30.899133Z","shell.execute_reply":"2022-06-29T03:09:15.230141Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}